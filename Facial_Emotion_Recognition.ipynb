{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 36420,
          "sourceType": "datasetVersion",
          "datasetId": 28577
        }
      ],
      "dockerImageVersionId": 30587,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Facial Emotion Recognition",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'fer2013:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F28577%2F36420%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240221%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240221T131726Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3e3fc5f5e50026b4983a4ea6e46652443df96192dd7e4c64181ed31b7e099713e19815f33a10bcb5aee07be429b3921c349d72809b6bf332d543cae014e78044a8d8d98f9ac7a47b81dbcc72eaff5dc73db95d68d4560eccbbea781ea235a1c3bb999cce78bdbaeb3124961b6ef5f1965eb26b06e9bcfd39281e7661a5d266389cb938e661ccc1ff0f77447a48ce65e9a88ed8f736c54d215e116cb93477703ce37e3f5b3fd5db7431d18732adf4e0bbeb481f33e82ea93f04de8af0c8bcdb55ef176019185354845a25df27c86b105628fd46729b33586f3df170d43158cd86a0088f1a24b9e59c99149e99add23961cb8751f3155f3fee628b67044b62e721'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "NEjqVtQw0FgP"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:00.047931Z",
          "iopub.execute_input": "2023-11-27T17:35:00.048335Z",
          "iopub.status.idle": "2023-11-27T17:35:00.0591Z",
          "shell.execute_reply.started": "2023-11-27T17:35:00.048304Z",
          "shell.execute_reply": "2023-11-27T17:35:00.057724Z"
        },
        "trusted": true,
        "id": "4BgFva1C0FgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:02.982434Z",
          "iopub.execute_input": "2023-11-27T17:35:02.982827Z",
          "iopub.status.idle": "2023-11-27T17:35:02.988414Z",
          "shell.execute_reply.started": "2023-11-27T17:35:02.982796Z",
          "shell.execute_reply": "2023-11-27T17:35:02.987316Z"
        },
        "trusted": true,
        "id": "w_WET8oo0FgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/fer2013/fer2013.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:09.573354Z",
          "iopub.execute_input": "2023-11-27T17:35:09.573742Z",
          "iopub.status.idle": "2023-11-27T17:35:12.965154Z",
          "shell.execute_reply.started": "2023-11-27T17:35:09.57371Z",
          "shell.execute_reply": "2023-11-27T17:35:12.964084Z"
        },
        "trusted": true,
        "id": "fZQYfy-00FgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:15.388811Z",
          "iopub.execute_input": "2023-11-27T17:35:15.389226Z",
          "iopub.status.idle": "2023-11-27T17:35:15.395057Z",
          "shell.execute_reply.started": "2023-11-27T17:35:15.389194Z",
          "shell.execute_reply": "2023-11-27T17:35:15.394284Z"
        },
        "trusted": true,
        "id": "5XXieflF0FgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:17.382735Z",
          "iopub.execute_input": "2023-11-27T17:35:17.383153Z",
          "iopub.status.idle": "2023-11-27T17:35:17.410444Z",
          "shell.execute_reply.started": "2023-11-27T17:35:17.38312Z",
          "shell.execute_reply": "2023-11-27T17:35:17.409283Z"
        },
        "trusted": true,
        "id": "qpn3ka9k0FgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# İlk birkaç satırı incele\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:19.735489Z",
          "iopub.execute_input": "2023-11-27T17:35:19.735952Z",
          "iopub.status.idle": "2023-11-27T17:35:19.748153Z",
          "shell.execute_reply.started": "2023-11-27T17:35:19.735906Z",
          "shell.execute_reply": "2023-11-27T17:35:19.746844Z"
        },
        "trusted": true,
        "id": "dr3pxK190FgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_usages = df['Usage'].unique()\n",
        "unique_usages"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:22.12713Z",
          "iopub.execute_input": "2023-11-27T17:35:22.127536Z",
          "iopub.status.idle": "2023-11-27T17:35:22.138394Z",
          "shell.execute_reply.started": "2023-11-27T17:35:22.127506Z",
          "shell.execute_reply": "2023-11-27T17:35:22.137241Z"
        },
        "trusted": true,
        "id": "kW92K_Tz0FgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_usages = df['Usage'].value_counts()\n",
        "\n",
        "# Bar grafiği oluştur\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=unique_usages.index, y=unique_usages.values, palette=\"viridis\")\n",
        "plt.title('Usage Sütunundaki Benzersiz Değerlerin Sayısı')\n",
        "plt.xlabel('Usage')\n",
        "plt.ylabel('Sayı')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:24.667627Z",
          "iopub.execute_input": "2023-11-27T17:35:24.6681Z",
          "iopub.status.idle": "2023-11-27T17:35:24.961694Z",
          "shell.execute_reply.started": "2023-11-27T17:35:24.668062Z",
          "shell.execute_reply": "2023-11-27T17:35:24.960893Z"
        },
        "trusted": true,
        "id": "zXrCiuT20Fga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Usage' sütununa göre train ve test setlerini ayırma\n",
        "train_set = df[df['Usage'] == 'Training']\n",
        "test_set = df[df['Usage'] == 'PrivateTest']\n",
        "\n",
        "# Train setinin bilgilerini göster\n",
        "print(\"Train setinin bilgileri:\")\n",
        "print(train_set.info())\n",
        "\n",
        "# Test setinin bilgilerini göster\n",
        "print(\"\\nTest setinin bilgileri:\")\n",
        "print(test_set.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:27.844048Z",
          "iopub.execute_input": "2023-11-27T17:35:27.844923Z",
          "iopub.status.idle": "2023-11-27T17:35:27.907143Z",
          "shell.execute_reply.started": "2023-11-27T17:35:27.84488Z",
          "shell.execute_reply": "2023-11-27T17:35:27.905948Z"
        },
        "trusted": true,
        "id": "fG2akZf50Fga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Duyguların dağılımını görselleştir\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='emotion', data=df)\n",
        "plt.title('Duyguların Dağılımı')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:30.199803Z",
          "iopub.execute_input": "2023-11-27T17:35:30.200259Z",
          "iopub.status.idle": "2023-11-27T17:35:30.501095Z",
          "shell.execute_reply.started": "2023-11-27T17:35:30.200221Z",
          "shell.execute_reply": "2023-11-27T17:35:30.499899Z"
        },
        "trusted": true,
        "id": "zHSzSKEH0Fgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek olarak 0.indeksteki görüntünün piksel değerlerini al\n",
        "sample_pixels = df['pixels'][0]\n",
        "\n",
        "# Piksel değerlerini diziye dönüştür\n",
        "pixel_array = np.array(sample_pixels.split(), dtype='int')\n",
        "\n",
        "# Görüntüyü yeniden şekillendir\n",
        "image = pixel_array.reshape(48, 48)\n",
        "\n",
        "# Görüntüyü görselleştir\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:33.47493Z",
          "iopub.execute_input": "2023-11-27T17:35:33.475479Z",
          "iopub.status.idle": "2023-11-27T17:35:33.761669Z",
          "shell.execute_reply.started": "2023-11-27T17:35:33.475432Z",
          "shell.execute_reply": "2023-11-27T17:35:33.759432Z"
        },
        "trusted": true,
        "id": "cT0m8jY60Fgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixels = df['pixels'].tolist()\n",
        "X = []\n",
        "for pixel_sequence in pixels:\n",
        "    face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "    face = np.asarray(face).reshape(48, 48)\n",
        "    X.append(face.astype('float32') / 255.0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:35:39.769807Z",
          "iopub.execute_input": "2023-11-27T17:35:39.770241Z",
          "iopub.status.idle": "2023-11-27T17:36:06.526184Z",
          "shell.execute_reply.started": "2023-11-27T17:35:39.770207Z",
          "shell.execute_reply": "2023-11-27T17:36:06.524836Z"
        },
        "trusted": true,
        "id": "4Bv6Flz60Fgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "X = np.expand_dims(X, -1) #boyut ekleme"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:36:06.528118Z",
          "iopub.execute_input": "2023-11-27T17:36:06.528466Z",
          "iopub.status.idle": "2023-11-27T17:36:06.801669Z",
          "shell.execute_reply.started": "2023-11-27T17:36:06.528435Z",
          "shell.execute_reply": "2023-11-27T17:36:06.800363Z"
        },
        "trusted": true,
        "id": "5MDc0J6Y0Fgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['emotion'].values\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:36:06.803065Z",
          "iopub.execute_input": "2023-11-27T17:36:06.803425Z",
          "iopub.status.idle": "2023-11-27T17:36:06.808885Z",
          "shell.execute_reply.started": "2023-11-27T17:36:06.803394Z",
          "shell.execute_reply": "2023-11-27T17:36:06.807425Z"
        },
        "trusted": true,
        "id": "db9rpDc60Fgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: preprocess_data fonksiyonu yaz."
      ],
      "metadata": {
        "id": "XrW5qiLc0Fgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bu işlemleri tek bir fonksiyonda toplamak daha sağlıklı olacak\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Veri ön işleme fonksiyonu:\n",
        "    - 'pixels' sütunundan görüntü verilerini çıkartma\n",
        "    - Görüntü verilerini normalize etme ve uygun şekle 48,48\n",
        "    - Etiket verilerini 'emotion' sütunundan çıkartma\n",
        "\n",
        "    Parameters:\n",
        "    - data: İşlenecek DataFrame\n",
        "\n",
        "    Returns:\n",
        "    - X: Giriş verileri (normalize ve uygun şekilde)\n",
        "    - y: Etiket verileri\n",
        "    \"\"\"\n",
        "\n",
        "    # 'pixels' sütununu kullanarak görüntü verilerini çıkartma\n",
        "    pixel_lists = df['pixels'].tolist()\n",
        "    images = []\n",
        "\n",
        "    # Her bir piksel dizisini işleme\n",
        "    for pixel_sequence in pixel_lists:\n",
        "        pixel_values = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        image = np.asarray(pixel_values).reshape(48, 48)\n",
        "        images.append(image.astype('float32') / 255.0)\n",
        "\n",
        "    # Giriş verilerini NumPy dizisine dönüştürme\n",
        "    X = np.array(images)\n",
        "\n",
        "    # Giriş verilerine kanal boyutu ekleyerek uygun şekle getirme\n",
        "    X = np.expand_dims(X, -1)\n",
        "\n",
        "    # Etiket verilerini 'emotion' sütunundan çıkartma\n",
        "    y = df['emotion'].values\n",
        "\n",
        "    return X, y\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:36:50.774721Z",
          "iopub.execute_input": "2023-11-27T17:36:50.775144Z",
          "iopub.status.idle": "2023-11-27T17:36:50.784471Z",
          "shell.execute_reply.started": "2023-11-27T17:36:50.77511Z",
          "shell.execute_reply": "2023-11-27T17:36:50.783222Z"
        },
        "trusted": true,
        "id": "8HIT2E700Fge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim ve test setlerini oluşturduktan sonra\n",
        "X_train, y_train = preprocess_data(train_set)\n",
        "X_test, y_test = preprocess_data(test_set)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:37:40.303017Z",
          "iopub.execute_input": "2023-11-27T17:37:40.303454Z",
          "iopub.status.idle": "2023-11-27T17:38:34.592825Z",
          "shell.execute_reply.started": "2023-11-27T17:37:40.303417Z",
          "shell.execute_reply": "2023-11-27T17:38:34.591664Z"
        },
        "trusted": true,
        "id": "IQharMG60Fgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kerası import edelim\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:38:41.864843Z",
          "iopub.execute_input": "2023-11-27T17:38:41.865309Z",
          "iopub.status.idle": "2023-11-27T17:38:56.557424Z",
          "shell.execute_reply.started": "2023-11-27T17:38:41.865274Z",
          "shell.execute_reply": "2023-11-27T17:38:56.556136Z"
        },
        "trusted": true,
        "id": "GKTRwQDz0Fgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "#relu aktivasyon , input shape i 48 48 1. 1-->gri\n",
        "model.add(MaxPooling2D((2, 2))) #Maksimum havuzlama (max pooling) katmanı.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu')) #ikinci katman. burada 64 adet\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten()) #Flatten katmanı\n",
        "\n",
        "#Tam bağlantılı bi gizli katman ekler. Bu katmanda 64 nöron bulunur,ReLU aktivasyon fonksiyonu kullanılır.\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "#Çıkış katmanı. Bu, 7 sınıflı bir duygu problemi için tasarlama için.\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:39:51.279925Z",
          "iopub.execute_input": "2023-11-27T17:39:51.280771Z",
          "iopub.status.idle": "2023-11-27T17:39:51.549615Z",
          "shell.execute_reply.started": "2023-11-27T17:39:51.280732Z",
          "shell.execute_reply": "2023-11-27T17:39:51.548434Z"
        },
        "trusted": true,
        "id": "NHjjqGLy0Fgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax aktivasyon fonksiyonu, çıkıştaki değerleri olasılıklara dönüştürür.her bir sınıfa ait olasılıkları elde etmenizi sağlar. Örneğin, bir görüntü için çıkış katmanındaki 7 nöronun değerleri 7 adet olur. Softmax aktivasyonu bu değerleri **normalize** eder, böylece toplam olasılık 1 olur ve bu, sınıflar arasında karşılaştırma yapmayı kolaylaştırır.\n",
        "\n",
        "bu değerlere göre girdinin hangi duyguda baskın olduğunu (oranı) tespit edeceğiz."
      ],
      "metadata": {
        "id": "7RfanKQw0Fgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:39:56.273446Z",
          "iopub.execute_input": "2023-11-27T17:39:56.273945Z",
          "iopub.status.idle": "2023-11-27T17:47:03.736069Z",
          "shell.execute_reply.started": "2023-11-27T17:39:56.2739Z",
          "shell.execute_reply": "2023-11-27T17:47:03.735187Z"
        },
        "trusted": true,
        "id": "LMKUn_700Fgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test veri setini\n",
        "X_test, y_test = preprocess_data(test_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:47:39.354905Z",
          "iopub.execute_input": "2023-11-27T17:47:39.355742Z",
          "iopub.status.idle": "2023-11-27T17:48:06.966976Z",
          "shell.execute_reply.started": "2023-11-27T17:47:39.355702Z",
          "shell.execute_reply": "2023-11-27T17:48:06.9657Z"
        },
        "trusted": true,
        "id": "mRR__pZZ0Fgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"\\nTest Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:48:34.063003Z",
          "iopub.execute_input": "2023-11-27T17:48:34.064227Z",
          "iopub.status.idle": "2023-11-27T17:48:49.942924Z",
          "shell.execute_reply.started": "2023-11-27T17:48:34.064177Z",
          "shell.execute_reply": "2023-11-27T17:48:49.941689Z"
        },
        "trusted": true,
        "id": "Tbw-dLMD0Fgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "epochs=10 iken sonuçlar:\n",
        "\n",
        "Test Loss: 1.4082423448562622\n",
        "\n",
        "Test Accuracy: 0.5210365056991577\n",
        "\n",
        "epochs=20 iken sonuçlar:\n",
        "\n",
        "Test Loss: 4.1522979736328125\n",
        "\n",
        "Test Accuracy: 0.4998606741428375\n",
        "\n",
        "**Sonuç olarak, bu durumda modelin performansının düştüğü ve daha önceki durumdan daha kötü tahminler yaptığı söylenebilir. **\n",
        "\n",
        "\n",
        "epochs=5 iken sonuçlar:\n",
        "\n",
        "Test Loss: 4.579214572906494\n",
        "\n",
        "Test Accuracy: 0.4920590817928314\n",
        "\n",
        "\n",
        "şuan denemelerimdeki en verimli 10 old. için 10da çalıştırıcam.\n",
        "\n",
        "todo: grid search fonksiyonuyla en iyi hiperparametre kombinasyonları bulunabilir."
      ],
      "metadata": {
        "id": "Y7sgXm9l0Fgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim sürecindeki metrikleri içeren geçmiş\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Kayıp ve doğruluk grafiği çizimi\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T16:04:15.771166Z",
          "iopub.execute_input": "2023-11-27T16:04:15.771631Z",
          "iopub.status.idle": "2023-11-27T16:09:15.743005Z",
          "shell.execute_reply.started": "2023-11-27T16:04:15.771595Z",
          "shell.execute_reply": "2023-11-27T16:09:15.741874Z"
        },
        "trusted": true,
        "id": "hL2WeeiG0Fgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin tahminleri\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# İlk 20 örneği inceleme\n",
        "for i in range(20):\n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    true_label = y_test[i]\n",
        "\n",
        "    print(f\"Örnek {i + 1} - Tahmin: {predicted_label}, Gerçek Etiket: {true_label}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-27T17:49:14.260513Z",
          "iopub.execute_input": "2023-11-27T17:49:14.260993Z",
          "iopub.status.idle": "2023-11-27T17:49:29.700856Z",
          "shell.execute_reply.started": "2023-11-27T17:49:14.260952Z",
          "shell.execute_reply": "2023-11-27T17:49:29.699587Z"
        },
        "trusted": true,
        "id": "77MYOr010Fgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: karmaşıklık matrisinde gösterim ekle"
      ],
      "metadata": {
        "id": "mg6zJb8_0Fgl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-o0yuFxB0Fgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}